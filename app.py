import streamlit as st
import google.generativeai as genai
from PIL import Image
import pandas as pd
import io
import json
import datetime
import re
import numpy as np

# --- é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(
    page_title="Gemini ç¨³å¥é˜Ÿåˆ—è¯Šæ–­",
    page_icon="ğŸš¦",
    layout="wide"
)

# --- åº”ç”¨æ ‡é¢˜å’Œè¯´æ˜ ---
st.title("ğŸš¦ Gemini æ™ºèƒ½è®¢å•è¯Šæ–­å·¥å…· V4.0 (ç¨³å¥é˜Ÿåˆ—ç‰ˆ)")
st.markdown("""
æ¬¢è¿ä½¿ç”¨æœ€ç¨³å®šçš„é˜Ÿåˆ—å¤„ç†ç‰ˆæœ¬ï¼æœ¬å·¥å…·ä¸ºè§£å†³äº‘ç«¯èµ„æºé™åˆ¶è€Œè®¾è®¡ï¼Œç¡®ä¿å¤§æ‰¹é‡å›¾ç‰‡ä¹Ÿèƒ½é€ä¸€æˆåŠŸå¤„ç†ã€‚
- **ä»»åŠ¡é˜Ÿåˆ—**ï¼šä¸Šä¼ çš„æ‰€æœ‰å›¾ç‰‡å°†è¿›å…¥ä¸€ä¸ªâ€œå¾…å¤„ç†â€é˜Ÿåˆ—ã€‚
- **é€ä¸€å¤„ç†**ï¼šç‚¹å‡»â€œå¤„ç†ä¸‹ä¸€å¼ â€æŒ‰é’®ï¼Œåº”ç”¨å°†ä¸€æ¬¡åªè¯†åˆ«ä¸€å¼ å›¾ç‰‡ï¼Œæœ‰æ•ˆé¿å…å†…å­˜æº¢å‡ºã€‚
- **çŠ¶æ€æ¸…æ™°**ï¼šæ—¶åˆ»äº†è§£å¤„ç†è¿›åº¦ï¼Œè¿˜å‰©å¤šå°‘å¼ å¾…å¤„ç†ã€‚
""")

# --- ä¼šè¯çŠ¶æ€ (Session State) åˆå§‹åŒ– ---
# æˆ‘ä»¬éœ€è¦æ›´å¤æ‚çš„çŠ¶æ€ç®¡ç†æ¥æ”¯æŒé˜Ÿåˆ—
if "file_list" not in st.session_state:
    st.session_state.file_list = [] # å­˜å‚¨æ‰€æœ‰ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
if "results" not in st.session_state:
    st.session_state.results = {} # å­˜å‚¨å·²è¯†åˆ«çš„ç»“æœ
if "processed_ids" not in st.session_state:
    st.session_state.processed_ids = [] # å­˜å‚¨å·²å¤„ç†æ–‡ä»¶çš„ID

# --- API å¯†é’¥é…ç½® å’Œ æ¨¡å‹åˆå§‹åŒ– ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    model = genai.GenerativeModel("gemini-1.5-pro-latest")
except Exception as e:
    st.error(f"åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API å¯†é’¥æˆ–æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®: {e}")
    st.stop()

# --- Prompt å’Œæ•°æ®æ¸…æ´—å‡½æ•° (ä¿æŒä¸å˜) ---
PROMPT_TEMPLATE = """...""" # çœç•¥ï¼Œå’ŒåŸæ¥ä¸€æ ·
def clean_and_convert_to_numeric(value):
    if value is None or not isinstance(value, str) or value.strip() == "": return np.nan
    numbers = re.findall(r'[\d\.]+', str(value))
    if numbers:
        try: return float(numbers[0])
        except (ValueError, IndexError): return np.nan
    return np.nan

# --- æ–‡ä»¶ä¸Šä¼ ä¸é˜Ÿåˆ—ç®¡ç† ---
st.header("STEP 1: ä¸Šä¼ æ‰€æœ‰è®¢å•å›¾ç‰‡")
uploaded_files = st.file_uploader(
    "è¯·åœ¨æ­¤å¤„ä¸Šä¼ ä¸€å¼ æˆ–å¤šå¼ å›¾ç‰‡",
    type=["jpg", "jpeg", "png"],
    accept_multiple_files=True
)

if uploaded_files:
    # æ›´æ–°æ–‡ä»¶åˆ—è¡¨ï¼ŒåŒæ—¶ä¿æŒç°æœ‰ç»“æœ
    st.session_state.file_list = uploaded_files

# --- é˜Ÿåˆ—å¤„ç†æ§åˆ¶ä¸­å¿ƒ ---
if st.session_state.file_list:
    files_to_process = [f for f in st.session_state.file_list if f.file_id not in st.session_state.processed_ids]
    
    st.header("STEP 2: é€ä¸€å¤„ç†è¯†åˆ«ä»»åŠ¡")
    
    if not files_to_process:
        st.success("ğŸ‰ æ‰€æœ‰å›¾ç‰‡å‡å·²å¤„ç†å®Œæ¯•ï¼è¯·åœ¨ä¸‹æ–¹æŸ¥çœ‹ã€ç¼–è¾‘å’Œå¯¼å‡ºç»“æœã€‚")
    else:
        total_count = len(st.session_state.file_list)
        remaining_count = len(files_to_process)
        st.info(f"**ä»»åŠ¡é˜Ÿåˆ—çŠ¶æ€**ï¼šå…± {total_count} å¼ å›¾ç‰‡ï¼Œè¿˜å‰© **{remaining_count}** å¼ å¾…å¤„ç†ã€‚")
        
        # è·å–é˜Ÿåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªä»»åŠ¡
        next_file_to_process = files_to_process[0]
        
        st.subheader(f"ä¸‹ä¸€ä¸ªå¾…å¤„ç†ï¼š**{next_file_to_process.name}**")
        st.image(next_file_to_process, width=200, caption="å¾…å¤„ç†å›¾ç‰‡é¢„è§ˆ")
        
        if st.button("ğŸ‘‰ å¤„ç†è¿™ä¸€å¼ ", use_container_width=True, type="primary"):
            with st.spinner(f"æ­£åœ¨è¯†åˆ« {next_file_to_process.name}..."):
                try:
                    file_id = next_file_to_process.file_id
                    image = Image.open(next_file_to_process).convert("RGB")
                    
                    response = model.generate_content([PROMPT_TEMPLATE, image])
                    cleaned_text = response.text.strip().removeprefix("```json").removesuffix("```").strip()
                    data = json.loads(cleaned_text)
                    
                    df = pd.DataFrame.from_records(data)
                    df.rename(columns={"æ•°é‡": "è¯†åˆ«æ•°é‡", "å•ä»·": "è¯†åˆ«å•ä»·", "æ€»ä»·": "è¯†åˆ«æ€»ä»·"}, inplace=True)
                    
                    # ... (è¯Šæ–­é€»è¾‘å’ŒV3.3å®Œå…¨ä¸€æ ·)
                    expected_cols = ["å“å", "è¯†åˆ«æ•°é‡", "è¯†åˆ«å•ä»·", "è¯†åˆ«æ€»ä»·"]
                    for col in expected_cols:
                        if col not in df.columns: df[col] = ""
                    df['æ•°é‡_num'] = df['è¯†åˆ«æ•°é‡'].apply(clean_and_convert_to_numeric)
                    df['å•ä»·_num'] = df['è¯†åˆ«å•ä»·'].apply(clean_and_convert_to_numeric)
                    df['æ€»ä»·_num'] = df['è¯†åˆ«æ€»ä»·'].apply(clean_and_convert_to_numeric)
                    df['è®¡ç®—æ€»ä»·'] = (df['æ•°é‡_num'] * df['å•ä»·_num']).round(2)
                    df['[æŒ‰æ€»ä»·]æ¨ç®—æ•°é‡'] = np.where(df['å•ä»·_num'] != 0, (df['æ€»ä»·_num'] / df['å•ä»·_num']).round(2), np.nan)
                    df['[æŒ‰æ€»ä»·]æ¨ç®—å•ä»·'] = np.where(df['æ•°é‡_num'] != 0, (df['æ€»ä»·_num'] / df['æ•°é‡_num']).round(2), np.nan)
                    df['çŠ¶æ€'] = np.where(np.isclose(df['è®¡ç®—æ€»ä»·'], df['æ€»ä»·_num']), 'âœ… ä¸€è‡´', 'âš ï¸ éœ€æ ¸å¯¹')
                    df.loc[df['è®¡ç®—æ€»ä»·'].isna() | df['æ€»ä»·_num'].isna(), 'çŠ¶æ€'] = 'â” ä¿¡æ¯ä¸è¶³'

                    final_cols = ["å“å", "è¯†åˆ«æ•°é‡", "è¯†åˆ«å•ä»·", "è¯†åˆ«æ€»ä»·", "è®¡ç®—æ€»ä»·", "[æŒ‰æ€»ä»·]æ¨ç®—æ•°é‡", "[æŒ‰æ€»ä»·]æ¨ç®—å•ä»·", "çŠ¶æ€"]
                    st.session_state.results[file_id] = df[final_cols]
                    
                    # æ ‡è®°æ­¤æ–‡ä»¶ä¸ºå·²å¤„ç†
                    st.session_state.processed_ids.append(file_id)
                    st.success(f"âœ… {next_file_to_process.name} å¤„ç†æˆåŠŸï¼")
                    st.rerun()

                except Exception as e:
                    st.error(f"å¤„ç† {next_file_to_process.name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    # å³ä½¿å¤±è´¥ï¼Œä¹Ÿæ ‡è®°ä¸ºå·²å¤„ç†ï¼Œé¿å…é˜Ÿåˆ—å¡ä½
                    st.session_state.processed_ids.append(next_file_to_process.file_id)
                    st.session_state.results[next_file_to_process.file_id] = pd.DataFrame([{"å“å": f"è¯†åˆ«å¤±è´¥: {e}", "çŠ¶æ€": "âŒ é”™è¯¯"}])
                    st.rerun()


# --- ç»“æœå±•ç¤ºä¸å¯¼å‡º ---
st.header("STEP 3: æŸ¥çœ‹ã€ç¼–è¾‘ä¸å¯¼å‡ºç»“æœ")
if not st.session_state.results:
    st.info("å°šæœªå¤„ç†ä»»ä½•å›¾ç‰‡ã€‚")
else:
    # æŒ‰ç…§ä¸Šä¼ é¡ºåºå±•ç¤ºç»“æœ
    for file in st.session_state.file_list:
        if file.file_id in st.session_state.results:
            with st.expander(f"ğŸ“„ è®¢å•ï¼š{file.name} (å·²å¤„ç†)", expanded=False):
                st.dataframe(st.session_state.results[file.file_id], use_container_width=True)

    # --- ç»Ÿä¸€ç¼–è¾‘ä¸å¯¼å‡º ---
    all_dfs = [df for df in st.session_state.results.values() if 'è¯†åˆ«æ•°é‡' in df.columns]
    if all_dfs:
        st.subheader("ç»Ÿä¸€ç¼–è¾‘åŒº")
        merged_df = pd.concat(all_dfs, ignore_index=True)
        edited_df = st.data_editor(
            merged_df,
            num_rows="dynamic",
            use_container_width=True,
            height=300,
            disabled=["è®¡ç®—æ€»ä»·", "[æŒ‰æ€»ä»·]æ¨ç®—æ•°é‡", "[æŒ‰æ€»ä»·]æ¨ç®—å•ä»·", "çŠ¶æ€"]
        )

        st.subheader("å¯¼å‡ºä¸º Excel æ–‡ä»¶")
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            edited_df.to_excel(writer, index=False, sheet_name='è¯Šæ–­ç»“æœ')
            writer.sheets['è¯Šæ–­ç»“æœ'].autofit()
        
        excel_data = output.getvalue()
        now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        file_name = f"è®¢å•è¯Šæ–­ç»“æœ_{now}.xlsx"
        
        st.download_button(
            label="âœ… ç‚¹å‡»ä¸‹è½½ã€è¯Šæ–­åã€‘çš„Excel",
            data=excel_data,
            file_name=file_name,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
