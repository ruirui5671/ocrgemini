import streamlit as st
import google.generativeai as genai
from PIL import Image
import pandas as pd
import io
import json
import datetime
import re
import numpy as np

# --- é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(
    page_title="Gemini ç¨³å¥é˜Ÿåˆ—è¯Šæ–­",
    page_icon="ğŸš¦",
    layout="wide"
)

# --- åº”ç”¨æ ‡é¢˜å’Œè¯´æ˜ ---
st.title("ğŸš¦ Gemini æ™ºèƒ½è®¢å•è¯Šæ–­å·¥å…· V4.2 (è‡ªåŠ¨æ‰¹å¤„ç†ç‰ˆ)")
st.markdown("""
æ¬¢è¿ä½¿ç”¨ï¼æœ¬ç‰ˆæœ¬å·²å‡çº§ä¸º **å…¨è‡ªåŠ¨æ‰¹å¤„ç†** æ¨¡å¼ã€‚
- **ä»»åŠ¡é˜Ÿåˆ—**ï¼šä¸Šä¼ çš„æ‰€æœ‰å›¾ç‰‡å°†è¿›å…¥ä¸€ä¸ªâ€œå¾…å¤„ç†â€é˜Ÿåˆ—ã€‚
- **è‡ªåŠ¨å¤„ç†**ï¼šç‚¹å‡»â€œå¼€å§‹æ‰¹é‡å¤„ç†â€ï¼Œåº”ç”¨å°†è‡ªåŠ¨é€ä¸€è¯†åˆ«é˜Ÿåˆ—ä¸­çš„æ‰€æœ‰å›¾ç‰‡ï¼Œæ— éœ€æ‰‹åŠ¨å¹²é¢„ã€‚
- **å®æ—¶è¿›åº¦**ï¼šå¤„ç†è¿‡ç¨‹ä¸­ï¼Œæ‚¨å¯ä»¥å®æ—¶çœ‹åˆ°é˜Ÿåˆ—çŠ¶æ€çš„å˜åŒ–ã€‚
- **éšæ—¶å¯åœ**ï¼šå¦‚æœéœ€è¦ï¼Œå¯ä»¥éšæ—¶ç‚¹å‡»â€œåœæ­¢å¤„ç†â€æ¥ä¸­æ–­ä»»åŠ¡ã€‚
""")

# --- ä¼šè¯çŠ¶æ€ (Session State) åˆå§‹åŒ– ---
if "file_list" not in st.session_state: st.session_state.file_list = []
if "results" not in st.session_state: st.session_state.results = {}
if "processed_ids" not in st.session_state: st.session_state.processed_ids = []
# âœ… æ ¸å¿ƒä¿®æ”¹ 1: æ–°å¢ä¸€ä¸ªçŠ¶æ€æ¥æ§åˆ¶æ˜¯å¦å¤„äºè‡ªåŠ¨å¤„ç†æ¨¡å¼
if "processing_active" not in st.session_state: st.session_state.processing_active = False

# --- å®‰å…¨è®¾ç½® ---
SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# --- API å¯†é’¥é…ç½® å’Œ æ¨¡å‹åˆå§‹åŒ– ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    model = genai.GenerativeModel("gemini-1.5-pro-latest", safety_settings=SAFETY_SETTINGS)
except Exception as e:
    st.error(f"åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API å¯†é’¥æˆ–æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®: {e}")
    st.stop()

# --- Prompt (ä¿æŒä¸å˜) ---
PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„ã€éå¸¸ä¸¥è°¨çš„è®¢å•æ•°æ®å½•å…¥ä¸“å®¶ã€‚
è¯·ä»”ç»†è¯†åˆ«è¿™å¼ æ‰‹å†™è®¢å•å›¾ç‰‡ï¼Œå¹¶æå–æ¯ä¸€è¡Œå•†å“çš„'å“å'ã€'æ•°é‡'ã€'å•ä»·'å’Œ'æ€»ä»·'ã€‚

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1.  æœ€ç»ˆå¿…é¡»è¾“å‡ºä¸€ä¸ªæ ¼å¼å®Œç¾çš„ JSON æ•°ç»„ã€‚
2.  æ•°ç»„ä¸­çš„æ¯ä¸€ä¸ª JSON å¯¹è±¡ä»£è¡¨ä¸€ä¸ªå•†å“ï¼Œä¸”å¿…é¡»åŒ…å«å››ä¸ªé”®ï¼š "å“å", "æ•°é‡", "å•ä»·", "æ€»ä»·"ã€‚
3.  å¦‚æœå›¾ç‰‡ä¸­çš„æŸä¸€è¡Œç¼ºå°‘æŸä¸ªä¿¡æ¯ï¼ˆä¾‹å¦‚æ²¡æœ‰å†™å•ä»·ï¼‰ï¼Œè¯·å°†å¯¹åº”çš„å€¼è®¾ä¸ºç©ºå­—ç¬¦ä¸² ""ã€‚
4.  å¦‚æœæŸä¸ªæ–‡å­—æˆ–æ•°å­—éå¸¸æ¨¡ç³Šï¼Œæ— æ³•ç¡®å®šï¼Œä¹Ÿè¯·è®¾ä¸ºç©ºå­—ç¬¦ä¸² ""ã€‚
5.  **ä½ çš„å›ç­”å¿…é¡»æ˜¯çº¯ç²¹çš„ã€å¯ä»¥ç›´æ¥è§£æçš„ JSON æ–‡æœ¬**ã€‚ç»å¯¹ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€è¯´æ˜æ–‡å­—ã€æˆ–è€… Markdown çš„ ```json ``` æ ‡è®°ã€‚
"""

# --- æ•°æ®æ¸…æ´—å‡½æ•° (ä¿æŒä¸å˜) ---
def clean_and_convert_to_numeric(value):
    if value is None or not isinstance(value, str) or value.strip() == "": return np.nan
    numbers = re.findall(r'[\d\.]+', str(value))
    if numbers:
        try: return float(numbers[0])
        except (ValueError, IndexError): return np.nan
    return np.nan

# --- æ–‡ä»¶ä¸Šä¼ ä¸é˜Ÿåˆ—ç®¡ç† ---
st.header("STEP 1: ä¸Šä¼ æ‰€æœ‰è®¢å•å›¾ç‰‡")
uploaded_files = st.file_uploader("è¯·åœ¨æ­¤å¤„ä¸Šä¼ ä¸€å¼ æˆ–å¤šå¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

# åªæœ‰åœ¨æœ‰æ–°æ–‡ä»¶ä¸Šä¼ æ—¶ï¼Œæ‰é‡ç½®é˜Ÿåˆ—çŠ¶æ€å¹¶å–æ¶ˆæ­£åœ¨è¿›è¡Œçš„å¤„ç†
if uploaded_files:
    # æ¯”è¾ƒæ–°æ—§æ–‡ä»¶åˆ—è¡¨ï¼Œå¦‚æœä¸åŒåˆ™æ›´æ–°
    new_file_ids = {f.file_id for f in uploaded_files}
    old_file_ids = {f.file_id for f in st.session_state.file_list}
    if new_file_ids != old_file_ids:
        st.session_state.file_list = uploaded_files
        st.session_state.results = {}
        st.session_state.processed_ids = []
        st.session_state.processing_active = False
        st.info("æ£€æµ‹åˆ°æ–°çš„æ–‡ä»¶åˆ—è¡¨ï¼Œå·²é‡ç½®å¤„ç†é˜Ÿåˆ—ã€‚")
        st.rerun() # å¼ºåˆ¶åˆ·æ–°ä»¥æ˜¾ç¤ºæœ€æ–°çŠ¶æ€


# --- é˜Ÿåˆ—å¤„ç†æ§åˆ¶ä¸­å¿ƒ ---
if st.session_state.file_list:
    files_to_process = [f for f in st.session_state.file_list if f.file_id not in st.session_state.processed_ids]
    total_count = len(st.session_state.file_list)
    remaining_count = len(files_to_process)
    processed_count = total_count - remaining_count

    st.header("STEP 2: è‡ªåŠ¨å¤„ç†è¯†åˆ«ä»»åŠ¡")
    
    # æ˜¾ç¤ºè¿›åº¦æ¡
    st.progress(processed_count / total_count if total_count > 0 else 0,
                text=f"å¤„ç†è¿›åº¦ï¼š{processed_count} / {total_count}")

    # âœ… æ ¸å¿ƒä¿®æ”¹ 2: æ›¿æ¢æ‰åŸæ¥çš„å•ä¸€æŒ‰é’®ï¼Œä½¿ç”¨å¼€å§‹/åœæ­¢æŒ‰é’®æ¥æ§åˆ¶è‡ªåŠ¨å¤„ç†æµç¨‹
    col1, col2 = st.columns(2)
    with col1:
        # åªæœ‰åœ¨æœªå¼€å§‹ä¸”æœ‰å¾…å¤„ç†æ–‡ä»¶æ—¶ï¼Œæ‰æ˜¾ç¤ºâ€œå¼€å§‹â€æŒ‰é’®
        if not st.session_state.processing_active and files_to_process:
            if st.button("ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†", use_container_width=True, type="primary"):
                st.session_state.processing_active = True
                st.rerun() # ç‚¹å‡»åç«‹å³é‡æ–°è¿è¡Œä»¥å¯åŠ¨å¤„ç†å¾ªç¯

    with col2:
        # åªæœ‰åœ¨å¤„ç†è¿›è¡Œä¸­æ—¶ï¼Œæ‰æ˜¾ç¤ºâ€œåœæ­¢â€æŒ‰é’®
        if st.session_state.processing_active:
            if st.button("â¹ï¸ åœæ­¢å¤„ç†", use_container_width=True):
                st.session_state.processing_active = False
                st.warning("å¤„ç†å·²æ‰‹åŠ¨åœæ­¢ã€‚")
                st.rerun() # é‡æ–°è¿è¡Œä»¥æ›´æ–°UIçŠ¶æ€

    # âœ… æ ¸å¿ƒä¿®æ”¹ 3: è‡ªåŠ¨å¤„ç†å¾ªç¯çš„ä¸»ä½“é€»è¾‘
    # å½“â€œè‡ªåŠ¨å¤„ç†â€å¼€å…³æ‰“å¼€ï¼Œå¹¶ä¸”è¿˜æœ‰æ–‡ä»¶å¾…å¤„ç†æ—¶ï¼Œæ‰§è¡Œæ­¤å—
    if st.session_state.processing_active and files_to_process:
        next_file_to_process = files_to_process[0]
        
        with st.spinner(f"æ­£åœ¨è¯†åˆ« {next_file_to_process.name}... (é˜Ÿåˆ—å‰©ä½™ {remaining_count-1} å¼ )"):
            try:
                file_id = next_file_to_process.file_id
                image = Image.open(next_file_to_process).convert("RGB")
                
                response = model.generate_content([PROMPT_TEMPLATE, image])
                
                if not response.text or not response.text.strip():
                    raise ValueError("æ¨¡å‹è¿”å›äº†ç©ºå†…å®¹ã€‚å¯èƒ½æ˜¯å›¾ç‰‡è´¨é‡é—®é¢˜æˆ–å®‰å…¨ç­–ç•¥è§¦å‘ã€‚")

                cleaned_text = response.text.strip().removeprefix("```json").removesuffix("```").strip()
                data = json.loads(cleaned_text)
                
                df = pd.DataFrame.from_records(data)
                df.rename(columns={"æ•°é‡": "è¯†åˆ«æ•°é‡", "å•ä»·": "è¯†åˆ«å•ä»·", "æ€»ä»·": "è¯†åˆ«æ€»ä»·"}, inplace=True)
                
                expected_cols = ["å“å", "è¯†åˆ«æ•°é‡", "è¯†åˆ«å•ä»·", "è¯†åˆ«æ€»ä»·"]
                for col in expected_cols:
                    if col not in df.columns: df[col] = ""

                df['æ•°é‡_num'] = df['è¯†åˆ«æ•°é‡'].apply(clean_and_convert_to_numeric)
                df['å•ä»·_num'] = df['è¯†åˆ«å•ä»·'].apply(clean_and_convert_to_numeric)
                df['æ€»ä»·_num'] = df['è¯†åˆ«æ€»ä»·'].apply(clean_and_convert_to_numeric)
                df['è®¡ç®—æ€»ä»·'] = (df['æ•°é‡_num'] * df['å•ä»·_num']).round(2)
                df['[æŒ‰æ€»ä»·]æ¨ç®—æ•°é‡'] = np.where(df['å•ä»·_num'] != 0, (df['æ€»ä»·_num'] / df['å•ä»·_num']).round(2), np.nan)
                df['[æŒ‰æ€»ä»·]æ¨ç®—å•ä»·'] = np.where(df['æ•°é‡_num'] != 0, (df['æ€»ä»·_num'] / df['æ•°é‡_num']).round(2), np.nan)
                df['çŠ¶æ€'] = np.where(np.isclose(df['è®¡ç®—æ€»ä»·'], df['æ€»ä»·_num']), 'âœ… ä¸€è‡´', 'âš ï¸ éœ€æ ¸å¯¹')
                df.loc[df['è®¡ç®—æ€»ä»·'].isna() | df['æ€»ä»·_num'].isna(), 'çŠ¶æ€'] = 'â” ä¿¡æ¯ä¸è¶³'

                final_cols = ["å“å", "è¯†åˆ«æ•°é‡", "è¯†åˆ«å•ä»·", "è¯†åˆ«æ€»ä»·", "è®¡ç®—æ€»ä»·", "[æŒ‰æ€»ä»·]æ¨ç®—æ•°é‡", "[æŒ‰æ€»ä»·]æ¨ç®—å•ä»·", "çŠ¶æ€"]
                st.session_state.results[file_id] = df[final_cols]
                st.session_state.processed_ids.append(file_id)

            except Exception as e:
                st.error(f"å¤„ç† {next_file_to_process.name} æ—¶å‡ºé”™: {e}")
                st.session_state.processed_ids.append(next_file_to_process.file_id)
                st.session_state.results[next_file_to_process.file_id] = pd.DataFrame([{"å“å": f"è¯†åˆ«å¤±è´¥", "çŠ¶æ€": "âŒ é”™è¯¯"}])
            
            # æ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½ç«‹å³é‡æ–°è¿è¡Œè„šæœ¬ä»¥å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
            st.rerun()

    # å½“é˜Ÿåˆ—å¤„ç†å®Œæˆæ—¶ï¼Œæ˜¾ç¤ºæœ€ç»ˆä¿¡æ¯
    if not files_to_process and total_count > 0:
        if st.session_state.processing_active:
            # å¦‚æœæ˜¯ä»å¤„ç†çŠ¶æ€åˆšåˆšå®Œæˆï¼Œåˆ™å…³é—­å¼€å…³å¹¶æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
            st.session_state.processing_active = False
            st.success("ğŸ‰ æ‰€æœ‰å›¾ç‰‡å‡å·²è‡ªåŠ¨å¤„ç†å®Œæ¯•ï¼")
            st.balloons()
            st.rerun() # æœ€åä¸€æ¬¡åˆ·æ–°ä»¥éšè—â€œåœæ­¢â€æŒ‰é’®
        else:
            # å¦‚æœæ˜¯é¡µé¢åŠ è½½æ—¶å°±å·²ç»å¤„ç†å®Œäº†ï¼Œåªæ˜¾ç¤ºæç¤º
            st.info("æ‰€æœ‰å›¾ç‰‡å‡å·²å¤„ç†ã€‚è¯·åœ¨ä¸‹æ–¹æŸ¥çœ‹ã€ç¼–è¾‘å’Œå¯¼å‡ºç»“æœã€‚")


# --- ç»“æœå±•ç¤ºä¸å¯¼å‡º (è¿™éƒ¨åˆ†æ— éœ€ä¿®æ”¹) ---
st.header("STEP 3: æŸ¥çœ‹ã€ç¼–è¾‘ä¸å¯¼å‡ºç»“æœ")

if not st.session_state.results:
    st.info("å°šæœªå¤„ç†ä»»ä½•å›¾ç‰‡ã€‚è¯·å…ˆä¸Šä¼ å¹¶å¼€å§‹å¤„ç†ã€‚")
else:
    # å±•å¼€æ‰€æœ‰å·²å¤„ç†çš„ç»“æœ
    for file in st.session_state.file_list:
        if file.file_id in st.session_state.results:
            with st.expander(f"ğŸ“„ è®¢å•ï¼š{file.name} (å·²å¤„ç†)", expanded=True):
                st.dataframe(st.session_state.results[file.file_id], use_container_width=True)

    # æ±‡æ€»æ‰€æœ‰å¯ç”¨çš„DataFrameç”¨äºç¼–è¾‘å’Œå¯¼å‡º
    all_dfs = [df for df in st.session_state.results.values() if isinstance(df, pd.DataFrame) and 'è¯†åˆ«æ•°é‡' in df.columns]
    if all_dfs:
        st.subheader("ç»Ÿä¸€ç¼–è¾‘åŒº")
        # å°†æ‰€æœ‰æˆåŠŸçš„è¯†åˆ«ç»“æœåˆå¹¶åˆ°ä¸€ä¸ªå¯ç¼–è¾‘çš„è¡¨æ ¼ä¸­
        merged_df = pd.concat(all_dfs, ignore_index=True)
        edited_df = st.data_editor(
            merged_df,
            num_rows="dynamic",
            use_container_width=True,
            height=300,
            disabled=["è®¡ç®—æ€»ä»·", "[æŒ‰æ€»ä»·]æ¨ç®—æ•°é‡", "[æŒ‰æ€»ä»·]æ¨ç®—å•ä»·", "çŠ¶æ€"]
        )
        
        st.subheader("å¯¼å‡ºä¸º Excel æ–‡ä»¶")
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            edited_df.to_excel(writer, index=False, sheet_name='è¯Šæ–­ç»“æœ')
            # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
            for column in edited_df:
                column_length = max(edited_df[column].astype(str).map(len).max(), len(column))
                col_idx = edited_df.columns.get_loc(column)
                writer.sheets['è¯Šæ–­ç»“æœ'].set_column(col_idx, col_idx, column_length + 2)
        excel_data = output.getvalue()
        now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        file_name = f"è®¢å•è¯Šæ–­ç»“æœ_{now}.xlsx"
        
        st.download_button(
            label="âœ… ç‚¹å‡»ä¸‹è½½ã€è¯Šæ–­åã€‘çš„Excel",
            data=excel_data,
            file_name=file_name,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
