import streamlit as st
import google.generativeai as genai
from PIL import Image
import pandas as pd
import io
import json
import datetime
import re
import numpy as np

# --- é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(
    page_title="Gemini æ™ºèƒ½è®¢å•è¯Šæ–­",
    page_icon="ğŸ•µï¸",
    layout="wide"
)

# --- åº”ç”¨æ ‡é¢˜å’Œè¯´æ˜ ---
st.title("ğŸ•µï¸ Gemini æ™ºèƒ½è®¢å•è¯Šæ–­å·¥å…· V3.0")
st.markdown("""
æ¬¢è¿ä½¿ç”¨å…·å¤‡ **æ ¹æºåˆ†æèƒ½åŠ›** çš„å…¨æ–°ç‰ˆæœ¬ï¼æœ¬å·¥å…·æ—¨åœ¨å¸®æ‚¨å¿«é€Ÿå®šä½è®¢å•ä¸­çš„æ½œåœ¨é”™è¯¯ã€‚
- **å¿ å®è¯†åˆ«**ï¼šå®Œæ•´å±•ç¤ºè¯†åˆ«å‡ºçš„ `æ•°é‡`ã€`å•ä»·` å’Œ `æ€»ä»·`ã€‚
- **è®¡ç®—å¯¹æ¯”**ï¼šç‹¬ç«‹è®¡ç®— `è¯†åˆ«æ•°é‡ Ã— è¯†åˆ«å•ä»·` çš„ç»“æœï¼Œä¾›æ‚¨ç›´æ¥å¯¹æ¯”ã€‚
- **æ™ºèƒ½è¯Šæ–­**ï¼šå½“è®¡ç®—ç»“æœä¸è¯†åˆ«æ€»ä»·ä¸ç¬¦æ—¶ï¼Œ**åå‘æ¨ç®—å‡ºå¯èƒ½çš„æ­£ç¡®æ•°å€¼**ï¼Œå¸®æ‚¨å¿«é€Ÿå®šä½ç¬”è¯¯æˆ–è¯†åˆ«é”™è¯¯ã€‚
""")

# --- API å¯†é’¥é…ç½® å’Œ æ¨¡å‹åˆå§‹åŒ– ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    model = genai.GenerativeModel("gemini-1.5-pro-latest")
except Exception as e:
    st.error(f"åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API å¯†é’¥æˆ–æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®: {e}")
    st.stop()


# --- Prompt ä¿æŒä¸å˜ï¼Œå®ƒè´Ÿè´£æŠ“å–æœ€åŸå§‹çš„æ•°æ® ---
PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„ã€éå¸¸ä¸¥è°¨çš„è®¢å•æ•°æ®å½•å…¥ä¸“å®¶ã€‚
è¯·ä»”ç»†è¯†åˆ«è¿™å¼ æ‰‹å†™è®¢å•å›¾ç‰‡ï¼Œå¹¶æå–æ¯ä¸€è¡Œå•†å“çš„'å“å'ã€'æ•°é‡'ã€'å•ä»·'å’Œ'æ€»ä»·'ã€‚

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1.  æœ€ç»ˆå¿…é¡»è¾“å‡ºä¸€ä¸ªæ ¼å¼å®Œç¾çš„ JSON æ•°ç»„ã€‚
2.  æ•°ç»„ä¸­çš„æ¯ä¸€ä¸ª JSON å¯¹è±¡ä»£è¡¨ä¸€ä¸ªå•†å“ï¼Œä¸”å¿…é¡»åŒ…å«å››ä¸ªé”®ï¼š "å“å", "æ•°é‡", "å•ä»·", "æ€»ä»·"ã€‚
3.  å¦‚æœå›¾ç‰‡ä¸­çš„æŸä¸€è¡Œç¼ºå°‘æŸä¸ªä¿¡æ¯ï¼ˆä¾‹å¦‚æ²¡æœ‰å†™å•ä»·ï¼‰ï¼Œè¯·å°†å¯¹åº”çš„å€¼è®¾ä¸ºç©ºå­—ç¬¦ä¸² ""ã€‚
4.  å¦‚æœæŸä¸ªæ–‡å­—æˆ–æ•°å­—éå¸¸æ¨¡ç³Šï¼Œæ— æ³•ç¡®å®šï¼Œä¹Ÿè¯·è®¾ä¸ºç©ºå­—ç¬¦ä¸² ""ã€‚
5.  **ä½ çš„å›ç­”å¿…é¡»æ˜¯çº¯ç²¹çš„ã€å¯ä»¥ç›´æ¥è§£æçš„ JSON æ–‡æœ¬**ã€‚ç»å¯¹ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€è¯´æ˜æ–‡å­—ã€æˆ–è€… Markdown çš„ ```json ``` æ ‡è®°ã€‚
"""

# --- ä¼šè¯çŠ¶æ€ (Session State) åˆå§‹åŒ– ---
if "results" not in st.session_state:
    st.session_state.results = {}

# --- æ•°æ®æ¸…æ´—å‡½æ•° ---
def clean_and_convert_to_numeric(value):
    if value is None or not isinstance(value, str) or value.strip() == "":
        return np.nan
    numbers = re.findall(r'[\d\.]+', str(value))
    if numbers:
        try:
            return float(numbers[0])
        except (ValueError, IndexError):
            return np.nan
    return np.nan

# --- æ–‡ä»¶ä¸Šä¼ ç»„ä»¶ ---
files = st.file_uploader(
    "ğŸ“¤ ä¸Šä¼ ä¸€å¼ æˆ–å¤šå¼ è®¢å•å›¾ç‰‡ (jpg, jpeg, png)",
    type=["jpg", "jpeg", "png"],
    accept_multiple_files=True
)

if files:
    for file in files:
        file_id = file.file_id
        
        with st.expander(f"ğŸ“· å›¾ç‰‡ï¼š{file.name}", expanded=True):
            col1, col2 = st.columns([0.8, 1.2]) # è®©å³è¾¹è¡¨æ ¼å®½ä¸€ç‚¹

            with col1:
                st.subheader("åŸå§‹å›¾ç‰‡")
                image = Image.open(file).convert("RGB")
                st.image(image, use_container_width=True)

            with col2:
                st.subheader("è¯†åˆ«ä¸è¯Šæ–­åˆ†æ")
                if st.button(f"ğŸš€ å¼€å§‹æ™ºèƒ½è¯Šæ–­", key=f"btn_{file_id}"):
                    with st.spinner("ğŸ•µï¸ Gemini æ­£åœ¨è¿›è¡Œè¯†åˆ«å’Œæ·±åº¦è¯Šæ–­..."):
                        try:
                            response = model.generate_content([PROMPT_TEMPLATE, image])
                            cleaned_text = response.text.strip().removeprefix("```json").removesuffix("```").strip()
                            data = json.loads(cleaned_text)
                            
                            # âœ… ä¸ºäº†æ¸…æ™°ï¼Œæ˜ç¡®é‡å‘½ååˆ—
                            df = pd.DataFrame.from_records(data)
                            df.rename(columns={
                                "æ•°é‡": "è¯†åˆ«æ•°é‡",
                                "å•ä»·": "è¯†åˆ«å•ä»·",
                                "æ€»ä»·": "è¯†åˆ«æ€»ä»·"
                            }, inplace=True)
                            
                            # --- âœ… æ ¸å¿ƒè¯Šæ–­é€»è¾‘å¼€å§‹ ---
                            # 1. ç¡®ä¿æ‰€æœ‰éœ€è¦çš„åˆ—éƒ½å­˜åœ¨
                            expected_cols = ["å“å", "è¯†åˆ«æ•°é‡", "è¯†åˆ«å•ä»·", "è¯†åˆ«æ€»ä»·"]
                            for col in expected_cols:
                                if col not in df.columns:
                                    df[col] = ""
                            
                            # 2. æ¸…æ´—æ‰€æœ‰è¯†åˆ«å‡ºçš„æ•°æ®ä¸ºæ•°å€¼
                            df['æ•°é‡_num'] = df['è¯†åˆ«æ•°é‡'].apply(clean_and_convert_to_numeric)
                            df['å•ä»·_num'] = df['è¯†åˆ«å•ä»·'].apply(clean_and_convert_to_numeric)
                            df['æ€»ä»·_num'] = df['è¯†åˆ«æ€»ä»·'].apply(clean_and_convert_to_numeric)
                            
                            # 3. è®¡ç®—â€œæ ‡å‡†ç­”æ¡ˆâ€æ€»ä»·
                            df['è®¡ç®—æ€»ä»·'] = (df['æ•°é‡_num'] * df['å•ä»·_num']).round(2)
                            
                            # 4. ã€å…³é”®ä¸€æ­¥ã€‘åå‘æ¨ç®—ï¼Œè¿›è¡Œè¯Šæ–­
                            def diagnose_discrepancy(row):
                                calc_total = row['è®¡ç®—æ€»ä»·']
                                rec_total = row['æ€»ä»·_num']
                                
                                # å¦‚æœä¿¡æ¯ä¸å…¨ï¼Œæ— æ³•è¯Šæ–­
                                if pd.isna(calc_total) or pd.isna(rec_total):
                                    return "â” ä¿¡æ¯ä¸è¶³"
                                
                                # å¦‚æœå®Œå…¨ä¸€è‡´
                                if np.isclose(calc_total, rec_total):
                                    return "âœ… å®Œå…¨ä¸€è‡´"
                                
                                # å¦‚æœä¸ä¸€è‡´ï¼Œå¼€å§‹è¯Šæ–­
                                suggestion = f"âš ï¸ ä¸ä¸€è‡´ (å·®é¢: {rec_total - calc_total:.2f})"
                                suggestions = []
                                
                                # è¯Šæ–­1: æ€»ä»·ä¸å˜ï¼Œæ•°é‡å¯èƒ½æ˜¯å¤šå°‘ï¼Ÿ
                                if row['å•ä»·_num'] != 0 and pd.notna(row['å•ä»·_num']):
                                    implied_qty = rec_total / row['å•ä»·_num']
                                    suggestions.append(f"æ•°é‡åº”ä¸º **{implied_qty:.2f}**")
                                
                                # è¯Šæ–­2: æ€»ä»·ä¸å˜ï¼Œå•ä»·å¯èƒ½æ˜¯å¤šå°‘ï¼Ÿ
                                if row['æ•°é‡_num'] != 0 and pd.notna(row['æ•°é‡_num']):
                                    implied_price = rec_total / row['æ•°é‡_num']
                                    suggestions.append(f"å•ä»·åº”ä¸º **{implied_price:.2f}**")
                                
                                if suggestions:
                                    suggestion += f"\nå¯èƒ½åŸå› : {' æˆ– '.join(suggestions)}"
                                    
                                return suggestion

                            df['å·®å¼‚è¯Šæ–­'] = df.apply(diagnose_discrepancy, axis=1)

                            # --- æ ¸å¿ƒè¯Šæ–­é€»è¾‘ç»“æŸ ---
                            
                            final_cols = ["å“å", "è¯†åˆ«æ•°é‡", "è¯†åˆ«å•ä»·", "è¯†åˆ«æ€»ä»·", "è®¡ç®—æ€»ä»·", "å·®å¼‚è¯Šæ–­"]
                            st.session_state.results[file_id] = df[final_cols]
                            
                            st.success("âœ… è¯Šæ–­å®Œæˆï¼è¯·æŸ¥çœ‹åˆ†æç»“æœã€‚")
                            st.rerun()

                        except json.JSONDecodeError:
                            st.error("âŒ ç»“æ„åŒ–è¯†åˆ«å¤±è´¥ï¼šæ¨¡å‹è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚")
                            st.info("æ¨¡å‹è¿”å›çš„åŸå§‹æ–‡æœ¬ï¼š")
                            st.text_area("åŸå§‹è¾“å‡º", cleaned_text if 'cleaned_text' in locals() else response.text, height=150)
                        except Exception as e:
                            st.error(f"âŒ å¤„ç†å¤±è´¥ï¼Œå‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{e}")

                if file_id in st.session_state.results:
                    st.dataframe(st.session_state.results[file_id], use_container_width=True)
                    st.caption("ä¸Šæ–¹ä¸ºè¯Šæ–­ç»“æœã€‚")

if st.session_state.results:
    st.divider()
    st.header("ğŸ“ ç»Ÿä¸€ç¼–è¾‘ä¸å¯¼å‡º")

    all_dfs = list(st.session_state.results.values())
    if all_dfs:
        # ä¸ºäº†é¿å…å¹²æ‰°ï¼Œå¯¼å‡ºæ—¶ä¸åŒ…å«è¯Šæ–­åˆ—ï¼Œåªå¯¼å‡ºå¹²å‡€çš„æ•°æ®
        export_cols = ["å“å", "è¯†åˆ«æ•°é‡", "è¯†åˆ«å•ä»·", "è¯†åˆ«æ€»ä»·", "è®¡ç®—æ€»ä»·"]
        merged_df = pd.concat(all_dfs, ignore_index=True)[export_cols]

        st.info("æ‚¨å¯ä»¥åœ¨ä¸‹è¡¨ä¸­ç›´æ¥ä¿®æ”¹ã€‚å»ºè®®å‚è€ƒä¸Šæ–¹çš„â€œå·®å¼‚è¯Šæ–­â€æ¥ä¿®æ­£â€œè¯†åˆ«æ•°é‡â€æˆ–â€œè¯†åˆ«å•ä»·â€ã€‚")
        edited_df = st.data_editor(
            merged_df,
            num_rows="dynamic",
            use_container_width=True,
            height=300
        )

        st.subheader("ğŸ“¥ å¯¼å‡ºä¸º Excel æ–‡ä»¶")
        
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            edited_df.to_excel(writer, index=False, sheet_name='è¯Šæ–­ç»“æœ')
            writer.sheets['è¯Šæ–­ç»“æœ'].autofit()
        
        excel_data = output.getvalue()
        now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        file_name = f"è®¢å•è¯Šæ–­ç»“æœ_{now}.xlsx"
        
        st.download_button(
            label="âœ… ç‚¹å‡»ä¸‹è½½ã€è¯Šæ–­åã€‘çš„Excel",
            data=excel_data,
            file_name=file_name,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
