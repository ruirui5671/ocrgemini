import streamlit as st
import google.generativeai as genai
from PIL import Image
import pandas as pd
import io
import json
import datetime
import re
import numpy as np

# --- é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(
    page_title="Gemini ç¨³å¥é˜Ÿåˆ—è¯Šæ–­",
    page_icon="ğŸ²",
    layout="wide"
)

# --- åº”ç”¨æ ‡é¢˜å’Œè¯´æ˜ ---
st.title("ğŸ² Gemini æ™ºèƒ½è®¢å•è¯Šæ–­å·¥å…· V4.4 (åˆ†ç±»ä¸åŠ¨æ€è®¡ç®—ç‰ˆ)")
st.markdown("""
æ¬¢è¿ä½¿ç”¨ï¼æœ¬ç‰ˆæœ¬åœ¨äº¤äº’å¼ç¼–è¾‘çš„åŸºç¡€ä¸Šï¼Œæ–°å¢ **æ™ºèƒ½åˆ†ç±»** ä¸ **åŠ¨æ€è®¡ç®—** åŠŸèƒ½ï¼
- **æ™ºèƒ½åˆ†ç±»**ï¼šAI ä¼šè‡ªåŠ¨å°†å•†å“å½’å…¥ `é±¼ç±»`ã€`è”¬èœç±»`ã€`è‚‰ç±»` ç­‰ç±»åˆ«ã€‚
- **åŠ¨æ€è®¡ç®—**ï¼šæ‚¨åœ¨è¡¨æ ¼ä¸­ä¿®æ”¹ `æ•°é‡` æˆ– `å•ä»·`åï¼Œ`è®¡ç®—æ€»ä»·` å’Œ `çŠ¶æ€` **ä¼šç«‹å³è‡ªåŠ¨æ›´æ–°**ï¼
- **å›¾è¡¨å¯¹ç…§**ï¼šåœ¨æ¯ä¸ªè¯†åˆ«ç»“æœæ—ç›´æ¥æ˜¾ç¤ºåŸå§‹å›¾ç‰‡ï¼Œæ ¸å¯¹ä¸€ç›®äº†ç„¶ã€‚
- **æ•°æ®è”åŠ¨**ï¼šæ‚¨åœ¨ä¸Šæ–¹ä»»ä½•è¡¨æ ¼ä¸­æ‰€åšçš„ä¿®æ”¹ï¼Œéƒ½ä¼š **ç«‹å³è‡ªåŠ¨åŒæ­¥** åˆ°ä¸‹æ–¹çš„æ±‡æ€»æ€»è¡¨åŠæœ€ç»ˆçš„Excelå¯¼å‡ºæ–‡ä»¶ä¸­ã€‚
""")

# --- ä¼šè¯çŠ¶æ€ (Session State) åˆå§‹åŒ– ---
if "file_list" not in st.session_state: st.session_state.file_list = []
if "results" not in st.session_state: st.session_state.results = {}
if "processed_ids" not in st.session_state: st.session_state.processed_ids = []
if "processing_active" not in st.session_state: st.session_state.processing_active = False

# --- å®‰å…¨è®¾ç½® ---
SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# --- API å¯†é’¥é…ç½® å’Œ æ¨¡å‹åˆå§‹åŒ– ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    model = genai.GenerativeModel("gemini-1.5-pro-latest", safety_settings=SAFETY_SETTINGS)
except Exception as e:
    st.error(f"åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API å¯†é’¥æˆ–æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®: {e}")
    st.stop()

# --- âœ… [V4.4 æ ¸å¿ƒå‡çº§] Prompt ---
PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„ã€éå¸¸ä¸¥è°¨çš„é¤é¥®è¡Œä¸šè®¢å•æ•°æ®å½•å…¥ä¸“å®¶ã€‚è®¢å•å†…å®¹ä¸»è¦æ˜¯é¤å…åå¨é‡‡è´­çš„é£Ÿæã€‚
è¯·ä»”ç»†è¯†åˆ«è¿™å¼ æ‰‹å†™è®¢å•å›¾ç‰‡ï¼Œå¹¶æå–æ¯ä¸€è¡Œå•†å“çš„'å“å'ã€'æ•°é‡'ã€'å•ä»·'å’Œ'æ€»ä»·'ï¼Œå¹¶å¯¹å•†å“è¿›è¡Œåˆ†ç±»ã€‚

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1.  æœ€ç»ˆå¿…é¡»è¾“å‡ºä¸€ä¸ªæ ¼å¼å®Œç¾çš„ JSON æ•°ç»„ã€‚
2.  æ•°ç»„ä¸­çš„æ¯ä¸€ä¸ª JSON å¯¹è±¡ä»£è¡¨ä¸€ä¸ªå•†å“ï¼Œä¸”å¿…é¡»åŒ…å«äº”ä¸ªé”®ï¼š "å“å", "æ•°é‡", "å•ä»·", "æ€»ä»·", "åˆ†ç±»"ã€‚
3.  æ–°å¢è§„åˆ™ï¼šè¯·ä¸ºæ¯ä¸ªå•†å“å¢åŠ ä¸€ä¸ª 'åˆ†ç±»' é”®ã€‚æ ¹æ®å•†å“åç§°ï¼Œå°†å…¶å½’å…¥ä»¥ä¸‹ç±»åˆ«ä¹‹ä¸€ï¼š'é±¼ç±»', 'çŒªè‚‰ç±»', 'é¸¡è‚‰ç±»', 'é¸­è‚‰ç±»', 'è”¬èœç±»', 'ç‰›è‚‰ç±»', 'ç¾Šè‚‰ç±»', 'è°ƒæ–™ç±»', 'æ¶ˆè€—å“ç±»'ã€‚å¦‚æœæ— æ³•åˆ¤æ–­ï¼Œå¯ä»¥è®¾ä¸º"å…¶ä»–"ã€‚
    - ç¤ºä¾‹: 'é»„é±¼' å½’å…¥ 'é±¼ç±»'; 'äº”èŠ±è‚‰' å½’å…¥ 'çŒªè‚‰ç±»'; 'é¦™èœ' å½’å…¥ 'è”¬èœç±»'; 'æ´—æ´ç²¾' å½’å…¥ 'æ¶ˆè€—å“ç±»'ã€‚
4.  å“åå’Œåˆ†ç±»å¿…é¡»æ˜¯æ–‡å­—ã€‚æ•°é‡ã€å•ä»·ã€æ€»ä»·åº”è¯¥æ˜¯æ•°å­—æˆ–èƒ½è§£æä¸ºæ•°å­—çš„å­—ç¬¦ä¸²ã€‚
5.  å¦‚æœå›¾ç‰‡ä¸­çš„æŸä¸€è¡Œç¼ºå°‘æŸä¸ªä¿¡æ¯ï¼ˆä¾‹å¦‚æ²¡æœ‰å†™å•ä»·ï¼‰ï¼Œè¯·å°†å¯¹åº”çš„å€¼è®¾ä¸ºç©ºå­—ç¬¦ä¸² ""ã€‚
6.  å¦‚æœæŸä¸ªæ–‡å­—æˆ–æ•°å­—éå¸¸æ¨¡ç³Šï¼Œæ— æ³•ç¡®å®šï¼Œä¹Ÿè¯·è®¾ä¸ºç©ºå­—ç¬¦ä¸² ""ã€‚
7.  **ä½ çš„å›ç­”å¿…é¡»æ˜¯çº¯ç²¹çš„ã€å¯ä»¥ç›´æ¥è§£æçš„ JSON æ–‡æœ¬**ã€‚ç»å¯¹ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€è¯´æ˜æ–‡å­—ã€æˆ–è€… Markdown çš„ ```json ``` æ ‡è®°ã€‚
"""

# --- æ•°æ®æ¸…æ´—ä¸è®¡ç®—å‡½æ•° ---
def clean_and_convert_to_numeric(value):
    if value is None or not isinstance(value, str) or value.strip() == "": return np.nan
    numbers = re.findall(r'[\d\.]+', str(value))
    if numbers:
        try: return float(numbers[0])
        except (ValueError, IndexError): return np.nan
    return np.nan

# âœ… [V4.4 æ ¸å¿ƒå‡çº§] æ–°å¢å¯é‡ç”¨çš„è®¡ç®—å‡½æ•°
def recalculate_dataframe(df):
    """å¯¹ç»™å®šçš„DataFrameè¿›è¡Œæ¸…æ´—ã€è®¡ç®—å’ŒçŠ¶æ€æ›´æ–°"""
    df_copy = df.copy()

    # ç¡®ä¿å…³é”®åˆ—å­˜åœ¨ï¼Œé˜²æ­¢ç”¨æˆ·åˆ é™¤åˆ—å¯¼è‡´æŠ¥é”™
    expected_cols = ["å“å", "åˆ†ç±»", "è¯†åˆ«æ•°é‡", "è¯†åˆ«å•ä»·", "è¯†åˆ«æ€»ä»·"]
    for col in expected_cols:
        if col not in df_copy.columns:
            df_copy[col] = ""

    # åº”ç”¨æ¸…æ´—å’Œè½¬æ¢
    df_copy['æ•°é‡_num'] = df_copy['è¯†åˆ«æ•°é‡'].apply(clean_and_convert_to_numeric)
    df_copy['å•ä»·_num'] = df_copy['è¯†åˆ«å•ä»·'].apply(clean_and_convert_to_numeric)
    df_copy['æ€»ä»·_num'] = df_copy['è¯†åˆ«æ€»ä»·'].apply(clean_and_convert_to_numeric)

    # é‡æ–°è®¡ç®—
    df_copy['è®¡ç®—æ€»ä»·'] = (df_copy['æ•°é‡_num'] * df_copy['å•ä»·_num']).round(2)
    df_copy['[æŒ‰æ€»ä»·]æ¨ç®—æ•°é‡'] = np.where(df_copy['å•ä»·_num'] != 0, (df_copy['æ€»ä»·_num'] / df_copy['å•ä»·_num']).round(2), np.nan)
    df_copy['[æŒ‰æ€»ä»·]æ¨ç®—å•ä»·'] = np.where(df_copy['æ•°é‡_num'] != 0, (df_copy['æ€»ä»·_num'] / df_copy['æ•°é‡_num']).round(2), np.nan)

    # é‡æ–°åˆ¤æ–­çŠ¶æ€ (equal_nan=True è®©ä¸¤ä¸ªNaNè¢«è§†ä¸ºä¸€è‡´)
    df_copy['çŠ¶æ€'] = np.where(np.isclose(df_copy['è®¡ç®—æ€»ä»·'], df_copy['æ€»ä»·_num'], equal_nan=True), 'âœ… ä¸€è‡´', 'âš ï¸ éœ€æ ¸å¯¹')
    df_copy.loc[df_copy['è®¡ç®—æ€»ä»·'].isna() | df_copy['æ€»ä»·_num'].isna(), 'çŠ¶æ€'] = 'â” ä¿¡æ¯ä¸è¶³'

    # å®šä¹‰æœ€ç»ˆåˆ—é¡ºåºï¼Œå¢åŠ äº†'åˆ†ç±»'
    final_cols = ["å“å", "åˆ†ç±»", "è¯†åˆ«æ•°é‡", "è¯†åˆ«å•ä»·", "è¯†åˆ«æ€»ä»·", "è®¡ç®—æ€»ä»·", "[æŒ‰æ€»ä»·]æ¨ç®—æ•°é‡", "[æŒ‰æ€»ä»·]æ¨ç®—å•ä»·", "çŠ¶æ€"]
    
    # ç¡®ä¿æ‰€æœ‰æœ€ç»ˆåˆ—éƒ½å­˜åœ¨
    for col in final_cols:
        if col not in df_copy.columns:
            df_copy[col] = np.nan
            
    return df_copy[final_cols]


# --- æ–‡ä»¶ä¸Šä¼ ä¸é˜Ÿåˆ—ç®¡ç† ---
st.header("STEP 1: ä¸Šä¼ æ‰€æœ‰è®¢å•å›¾ç‰‡")
uploaded_files = st.file_uploader("è¯·åœ¨æ­¤å¤„ä¸Šä¼ ä¸€å¼ æˆ–å¤šå¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"], accept_multiple_files=True)
if uploaded_files:
    new_file_ids = {f.file_id for f in uploaded_files}
    old_file_ids = {f.file_id for f in st.session_state.file_list}
    if new_file_ids != old_file_ids:
        st.session_state.file_list = uploaded_files
        st.session_state.results = {}
        st.session_state.processed_ids = []
        st.session_state.processing_active = False
        st.info("æ£€æµ‹åˆ°æ–°çš„æ–‡ä»¶åˆ—è¡¨ï¼Œå·²é‡ç½®å¤„ç†é˜Ÿåˆ—ã€‚")
        st.rerun()

# --- é˜Ÿåˆ—å¤„ç†æ§åˆ¶ä¸­å¿ƒ ---
if st.session_state.file_list:
    files_to_process = [f for f in st.session_state.file_list if f.file_id not in st.session_state.processed_ids]
    total_count = len(st.session_state.file_list)
    remaining_count = len(files_to_process)
    processed_count = total_count - remaining_count

    st.header("STEP 2: è‡ªåŠ¨å¤„ç†è¯†åˆ«ä»»åŠ¡")
    st.progress(processed_count / total_count if total_count > 0 else 0, text=f"å¤„ç†è¿›åº¦ï¼š{processed_count} / {total_count}")

    col1, col2 = st.columns(2)
    with col1:
        if not st.session_state.processing_active and files_to_process:
            if st.button("ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†", use_container_width=True, type="primary"):
                st.session_state.processing_active = True
                st.rerun()
    with col2:
        if st.session_state.processing_active:
            if st.button("â¹ï¸ åœæ­¢å¤„ç†", use_container_width=True):
                st.session_state.processing_active = False
                st.warning("å¤„ç†å·²æ‰‹åŠ¨åœæ­¢ã€‚")
                st.rerun()

    if st.session_state.processing_active and files_to_process:
        next_file_to_process = files_to_process[0]
        with st.spinner(f"æ­£åœ¨è¯†åˆ« {next_file_to_process.name}... (é˜Ÿåˆ—å‰©ä½™ {remaining_count-1} å¼ )"):
            try:
                file_id = next_file_to_process.file_id
                image = Image.open(next_file_to_process).convert("RGB")
                response = model.generate_content([PROMPT_TEMPLATE, image])
                if not response.text or not response.text.strip():
                    raise ValueError("æ¨¡å‹è¿”å›äº†ç©ºå†…å®¹ã€‚å¯èƒ½æ˜¯å›¾ç‰‡è´¨é‡é—®é¢˜æˆ–å®‰å…¨ç­–ç•¥è§¦å‘ã€‚")

                cleaned_text = response.text.strip().removeprefix("```json").removesuffix("```").strip()
                data = json.loads(cleaned_text)
                df = pd.DataFrame.from_records(data)
                df.rename(columns={"æ•°é‡": "è¯†åˆ«æ•°é‡", "å•ä»·": "è¯†åˆ«å•ä»·", "æ€»ä»·": "è¯†åˆ«æ€»ä»·"}, inplace=True)
                
                # âœ… [V4.4 æ ¸å¿ƒå‡çº§] è°ƒç”¨é‡æ„çš„è®¡ç®—å‡½æ•°
                processed_df = recalculate_dataframe(df)

                st.session_state.results[file_id] = processed_df
                st.session_state.processed_ids.append(file_id)
            except Exception as e:
                st.error(f"å¤„ç† {next_file_to_process.name} æ—¶å‡ºé”™: {e}")
                st.session_state.processed_ids.append(next_file_to_process.file_id)
                st.session_state.results[next_file_to_process.file_id] = pd.DataFrame([{"å“å": f"è¯†åˆ«å¤±è´¥", "çŠ¶æ€": "âŒ é”™è¯¯"}])
            st.rerun()

    if not files_to_process and total_count > 0:
        if st.session_state.processing_active:
            st.session_state.processing_active = False
            st.success("ğŸ‰ æ‰€æœ‰å›¾ç‰‡å‡å·²è‡ªåŠ¨å¤„ç†å®Œæ¯•ï¼")
            st.balloons()
            st.rerun()
        else:
            st.info("æ‰€æœ‰å›¾ç‰‡å‡å·²å¤„ç†ã€‚è¯·åœ¨ä¸‹æ–¹æŸ¥çœ‹ã€ç¼–è¾‘å’Œå¯¼å‡ºç»“æœã€‚")


# --- âœ… [V4.4 æ ¸å¿ƒä¿®æ”¹] ç»“æœå±•ç¤ºã€ç¼–è¾‘ä¸åŠ¨æ€è®¡ç®— ---
st.header("STEP 3: å¯¹ç…§å›¾ç‰‡ï¼Œç¼–è¾‘ç»“æœï¼ˆç¼–è¾‘åè‡ªåŠ¨é‡ç®—ï¼‰")

if not st.session_state.results:
    st.info("å°šæœªå¤„ç†ä»»ä½•å›¾ç‰‡ã€‚è¯·å…ˆä¸Šä¼ å¹¶å¼€å§‹å¤„ç†ã€‚")
else:
    for file in st.session_state.file_list:
        if file.file_id in st.session_state.results:
            st.markdown("---")
            st.subheader(f"ğŸ“„ è®¢å•ï¼š{file.name}")
            
            col_img, col_editor = st.columns([1, 2])

            with col_img:
                st.image(file, caption="åŸå§‹è®¢å•å›¾ç‰‡", use_column_width=True)

            with col_editor:
                current_df = st.session_state.results[file.file_id]
                
                # æ•è·ç”¨æˆ·ç¼–è¾‘åçš„ DataFrame
                edited_df = st.data_editor(
                    current_df,
                    key=f"editor_{file.file_id}",
                    num_rows="dynamic",
                    use_container_width=True,
                    # ç¦ç”¨è‡ªåŠ¨è®¡ç®—çš„åˆ—ï¼Œä½†å…è®¸ç”¨æˆ·ä¿®æ”¹ "åˆ†ç±»"
                    disabled=["è®¡ç®—æ€»ä»·", "[æŒ‰æ€»ä»·]æ¨ç®—æ•°é‡", "[æŒ‰æ€»ä»·]æ¨ç®—å•ä»·", "çŠ¶æ€"]
                )

                # âœ… [V4.4 æ ¸å¿ƒå‡çº§] åŠ¨æ€è®¡ç®—ï¼šå¯¹ç¼–è¾‘åçš„æ•°æ®ç«‹å³é‡æ–°è®¡ç®—
                recalculated_edited_df = recalculate_dataframe(edited_df)
                
                # å°†å®Œå…¨æ›´æ–°ï¼ˆåŒ…å«æœ€æ–°è®¡ç®—ç»“æœï¼‰çš„ DataFrame å†™å› session_state
                st.session_state.results[file.file_id] = recalculated_edited_df

    # --- æ±‡æ€»é¢„è§ˆä¸å¯¼å‡º ---
    st.markdown("---")
    st.header("STEP 4: é¢„è§ˆæ±‡æ€»ç»“æœå¹¶å¯¼å‡º")

    # ä» session_state ä¸­æ”¶é›†æ‰€æœ‰ï¼ˆå¯èƒ½å·²è¢«ç¼–è¾‘å’Œé‡ç®—è¿‡çš„ï¼‰DataFrame
    all_dfs = [df for df in st.session_state.results.values() if isinstance(df, pd.DataFrame) and 'è¯†åˆ«æ•°é‡' in df.columns]
    
    if all_dfs:
        st.subheader("ç»Ÿä¸€ç»“æœé¢„è§ˆåŒº (æ ¹æ®æ‚¨çš„ä¿®æ”¹å®æ—¶æ›´æ–°)")
        
        merged_df = pd.concat(all_dfs, ignore_index=True)
        
        st.dataframe(merged_df, use_container_width=True, height=300)
        
        st.subheader("å¯¼å‡ºä¸º Excel æ–‡ä»¶")
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            merged_df.to_excel(writer, index=False, sheet_name='è¯Šæ–­ç»“æœ')
            worksheet = writer.sheets['è¯Šæ–­ç»“æœ']
            for i, col in enumerate(merged_df.columns):
                column_len = max(merged_df[col].astype(str).map(len).max(), len(col)) + 2
                worksheet.set_column(i, i, column_len)

        excel_data = output.getvalue()
        now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        file_name = f"è®¢å•è¯Šæ–­ç»“æœ_{now}.xlsx"
        
        st.download_button(
            label="âœ… ç‚¹å‡»ä¸‹è½½ã€æœ€ç»ˆä¿®æ­£åã€‘çš„Excel",
            data=excel_data,
            file_name=file_name,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
